#pragma once

// Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// The C++ API for DeepSparse.

#include "libdeepsparse/compiler.hpp"
#include "libdeepsparse/config.hpp"
#include "libdeepsparse/dimensions.hpp"
#include "libdeepsparse/tensor.hpp"

#include <memory>
#include <string>
#include <vector>

namespace deepsparse
{

struct engine_config_t;
class engine_context_t;

// Engine_contexts can be used to run multiple engines with the same scheduler.
// This is useful for running multiple models concurrently in a server-like
// environment. The caller can use the make_engine_context function to
// instantiate an engine_context object and then pass it into all future calls
// to the engine constructor.
std::shared_ptr<engine_context_t> make_engine_context(size_t num_cores,
                                                      size_t num_streams);

///  engine_t loads and executes models.
class EXPORT engine_t
{
public:
    /// Load and prepare model specified by config.
    ///
    /// @param config  Engine parameters for model.
    //
    /// @throw  std::exception for bad model or other loading issues.
    explicit engine_t(engine_config_t const& config);

    explicit engine_t(multi_engine_config_t const& config);

    /// Destructor of the engine.
    ~engine_t() = default;

    /// Run this set of input tensors through the model.
    ///
    /// @param inputs The collection of model input tensors.
    ///
    /// @return Output tensors generated by the model.
    tensors_t execute(tensors_t const& inputs);

    /// @return Engine configuration.
    engine_config_t config() const;

    /// @return Model file path
    std::string model_file_path() const;

    /// @return Count of the input tensors.
    /// The index range from 0 to num-1, inclusive.
    size_t num_inputs() const;

    /// @return Count of the output tensors.
    size_t num_outputs() const;

    /// @return The name of input tensor at index.
    std::string input_name(size_t const index) const;

    /// @return The name of output tensor at index.
    std::string output_name(size_t const index) const;

    /// @return The element type of input tensor at index.
    std::optional<element_type_t> input_element_type(size_t const index) const;

    /// @return The element type of output tensor at index.
    std::optional<element_type_t> output_element_type(size_t const index) const;

    /// @return Dimensions of tensor at index.
    std::optional<dimensions_t> input_dimensions(size_t const index) const;

    /// Dimensions of the current output tensor at index.
    ///
    /// Output shapes are based on the values of the current inputs. When
    /// possible the engine will infer precise output dimensions. If this is not
    /// possible, then std::nullopt is returned.
    std::optional<dimensions_t> output_dimensions(size_t const index) const;

private:
    std::shared_ptr<void> imp_;
    std::string           model_file_path_;
};

/// @return Vector of random tensors for each input not in graph initializer
/// list.
EXPORT tensors_t
generate_random_inputs(engine_t const&             engine,
                       std::optional<double> const fmin_val = std::nullopt,
                       std::optional<double> const fmax_val = std::nullopt);

/// Load the data in the files. If there are more then one file on path in the
/// paths collection, the data in each file is considered a subtensor and each
/// file is accumulated into a batched tensor.
EXPORT tensors_t load_inputs(std::vector<std::string> const& paths);

/// Test if a and b are close.
///
/// @return True if a and b satisfy absolute(a-b) <= (atol + rtol * absolute(b))
///
/// Asserts if a and b differ in shape or element type.
EXPORT bool
allclose(tensors_t const& a, tensors_t const& b, double atol, double rtol);

/// @return max elementwise difference between a and b
///
/// Asserts if a and b have differ in shape or element type.
EXPORT double
maxdiff(tensors_t const& a, tensors_t const& b, double atol, double rtol);

} // namespace deepsparse
